{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hZwRFvUXkGf"
      },
      "source": [
        "Installing Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfTGu871aGdC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "232ebc40-5349-47da-bbc9-52d0c6277a39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting iglovikov_helper_functions\n",
            "  Downloading iglovikov_helper_functions-0.0.53-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from iglovikov_helper_functions)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting imagecorruptions (from iglovikov_helper_functions)\n",
            "  Downloading imagecorruptions-1.1.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from iglovikov_helper_functions) (1.2.0)\n",
            "Collecting jpeg4py (from iglovikov_helper_functions)\n",
            "  Downloading jpeg4py-0.1.4.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from iglovikov_helper_functions) (1.22.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from iglovikov_helper_functions) (4.7.0.72)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from iglovikov_helper_functions) (1.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from iglovikov_helper_functions) (8.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from iglovikov_helper_functions) (0.19.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from iglovikov_helper_functions) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from iglovikov_helper_functions) (1.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from iglovikov_helper_functions) (2.0.1+cu118)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->iglovikov_helper_functions) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->iglovikov_helper_functions) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->iglovikov_helper_functions) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->iglovikov_helper_functions) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->iglovikov_helper_functions) (23.1)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from jpeg4py->iglovikov_helper_functions) (1.15.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->iglovikov_helper_functions) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->iglovikov_helper_functions) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->iglovikov_helper_functions) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->iglovikov_helper_functions) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->iglovikov_helper_functions) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->iglovikov_helper_functions) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->iglovikov_helper_functions) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->iglovikov_helper_functions) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->iglovikov_helper_functions) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->iglovikov_helper_functions) (16.0.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->iglovikov_helper_functions) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->jpeg4py->iglovikov_helper_functions) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->iglovikov_helper_functions) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->iglovikov_helper_functions) (1.3.0)\n",
            "Building wheels for collected packages: jpeg4py\n",
            "  Building wheel for jpeg4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jpeg4py: filename=jpeg4py-0.1.4-py3-none-any.whl size=8424 sha256=a26e2b9552929762c62a5f75cb85a9f1feacedcd6e9b5853e53577d7a9fb46fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/c3/0f/348e6cadb3a27435e833d21d91707d653fb159d69f2a867a36\n",
            "Successfully built jpeg4py\n",
            "Installing collected packages: addict, jpeg4py, imagecorruptions, iglovikov_helper_functions\n",
            "Successfully installed addict-2.4.0 iglovikov_helper_functions-0.0.53 imagecorruptions-1.1.2 jpeg4py-0.1.4\n"
          ]
        }
      ],
      "source": [
        "!pip install iglovikov_helper_functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icFPsCkKaaB_"
      },
      "source": [
        "Installing cloth segmentation module from pypi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFaXIr2YaSUX"
      },
      "outputs": [],
      "source": [
        "!pip install cloths_segmentation  > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fVuyHf6zstb"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6onfhgabLfi"
      },
      "source": [
        "Importing necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_goHaGlBjZf"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yx4oLfemz4ys"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mp2G_NgPBByg"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tC_aZXqr_4np"
      },
      "outputs": [],
      "source": [
        "import albumentations as albu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPfDG7jKz1FF"
      },
      "outputs": [],
      "source": [
        "from pylab import imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxYdTHyIZj93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d33efbde-978f-438a-9a01-45440ebe06c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#trying to save on google drive, so, mounting it to my google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') # connects Colab to your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt\n",
        "!pip install TensorRT\n",
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/clothkart/pose_estimationnew')\n",
        "!python run_webcam.py --image  test.jpeg"
      ],
      "metadata": {
        "id": "h-1UDJmoX3Rt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d39997ff-a52b-42da-d044-0b761a910cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/ppwwyyxx/tensorpack.git (from -r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 13))\n",
            "  Cloning https://github.com/ppwwyyxx/tensorpack.git to /tmp/pip-req-build-hpjp6p_e\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ppwwyyxx/tensorpack.git /tmp/pip-req-build-hpjp6p_e\n",
            "  Resolved https://github.com/ppwwyyxx/tensorpack.git to commit a9a2660d9ebe8fe4f32693b59f1e003687716d81\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting argparse (from -r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 1))\n",
            "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 2)) (0.3.6)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 3)) (0.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 5)) (0.56.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 6)) (5.9.5)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 7)) (2.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 8)) (2.27.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 9)) (0.19.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 10)) (1.10.1)\n",
            "Requirement already satisfied: slidingwindow in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 11)) (0.0.14)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 12)) (4.65.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 4)) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 4)) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 4)) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 4)) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 4)) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 5)) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 5)) (67.7.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 8)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 8)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 8)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 8)) (3.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 9)) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 9)) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 9)) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from tensorpack==0.11->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 13)) (0.8.10)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from tensorpack==0.11->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 13)) (1.0.5)\n",
            "Requirement already satisfied: msgpack-numpy>=0.4.4.2 in /usr/local/lib/python3.10/dist-packages (from tensorpack==0.11->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 13)) (0.4.8)\n",
            "Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.10/dist-packages (from tensorpack==0.11->-r /content/gdrive/MyDrive/clothkart/pose_estimationnew/requirements.txt (line 13)) (23.2.1)\n",
            "Installing collected packages: argparse\n",
            "Successfully installed argparse-1.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting TensorRT\n",
            "  Downloading tensorrt-8.6.1.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: TensorRT\n",
            "  Building wheel for TensorRT (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for TensorRT: filename=tensorrt-8.6.1-py2.py3-none-any.whl size=16973 sha256=30e8943abbf13c4ccf25e2cabe6a53fed9d742669d2032df7883cb98051cefc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/29/56/abdffd4c604f255b5254bef3f1c598ab7811ea020540599438\n",
            "Successfully built TensorRT\n",
            "Installing collected packages: TensorRT\n",
            "Successfully installed TensorRT-8.6.1\n",
            "2023-06-07 10:55:40.851564: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-07 10:55:42.442907: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/MyDrive/clothkart/pose_estimationnew/run_webcam.py\", line 8, in <module>\n",
            "    from tf_pose.estimator import TfPoseEstimator\n",
            "  File \"/content/gdrive/MyDrive/clothkart/pose_estimationnew/tf_pose/__init__.py\", line 5, in <module>\n",
            "    from tf_pose.runner import infer, Estimator, get_estimator\n",
            "  File \"/content/gdrive/MyDrive/clothkart/pose_estimationnew/tf_pose/runner.py\", line 8, in <module>\n",
            "    from tf_pose import eval\n",
            "  File \"/content/gdrive/MyDrive/clothkart/pose_estimationnew/tf_pose/eval.py\", line 13, in <module>\n",
            "    from tf_pose.estimator import TfPoseEstimator\n",
            "  File \"/content/gdrive/MyDrive/clothkart/pose_estimationnew/tf_pose/estimator.py\", line 17, in <module>\n",
            "    from tf_pose.pafprocess import pafprocess\n",
            "  File \"/content/gdrive/MyDrive/clothkart/pose_estimationnew/tf_pose/pafprocess/pafprocess.py\", line 10, in <module>\n",
            "    from . import _pafprocess\n",
            "ImportError: cannot import name '_pafprocess' from 'tf_pose.pafprocess' (/content/gdrive/MyDrive/clothkart/pose_estimationnew/tf_pose/pafprocess/__init__.py)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCr1TZRNZrXQ"
      },
      "source": [
        "If you want to use cloth segmentation on images from gallary, run below code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3SyOFvZZcf8"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import files\n",
        "img = files.upload()\n",
        "keys = list(img) # list of all image names from dictionary of images uploaded\n",
        "allowefileformats = ['jpg','png','bmp','jpeg']\n",
        "if len(img)!=1:\n",
        "  print('Please Select only one image file')\n",
        "\n",
        "elif keys[0].split('.')[-1] not in allowefileformats:\n",
        "  print('Please select an image in formats: ',allowefileformats)\n",
        "\n",
        "img_data = img[keys[-1]]\n",
        "img_path = '/content/gdrive/MyDrive/project/result/cloth_segmentation/test_imagephoto.jpg'+keys[-1] # set root path to folder where you uploaded the data\n",
        "with open(img_path,'wb') as f:\n",
        "  f.write(img_data)\n",
        "#image = load_rgb(img_path) #if this line will be uncommented, comment out below three lines\n",
        "\n",
        "#from PIL import Image\n",
        "#from io import BytesIO\n",
        "#image = Image.open(BytesIO(img[keys[0]]))#----- this is related to below line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrA_2m7UW_yv"
      },
      "source": [
        "Program to open web camera in google colab and take picture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuuPwhjeap7_"
      },
      "source": [
        "If you want to use cloth segmentation on webcam captured image, run below code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32BK2-G3yL1l"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  img_path = '/content/gdrive/My Drive/project/result/cloth_segmentation/test_image'+filename # set root path to folder where you uploaded the data\n",
        "  with open(img_path, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return img_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_snDceYKXJIg"
      },
      "source": [
        "Calling Above function to run and capture the photo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAniqJP2XSH_"
      },
      "outputs": [],
      "source": [
        "from google.colab import files as FILE\n",
        "from IPython.display import Image\n",
        "try:\n",
        "  img_path = take_photo()\n",
        "  print('Saved to {}'.format(img_path))\n",
        "  FILE.download('image_name.jpg')\n",
        "  # Show the image which was just taken.\n",
        "  display(Image(img_path))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbDR02FpXslG"
      },
      "source": [
        "Importing Important things from helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgZbmE9f_Vf-"
      },
      "outputs": [],
      "source": [
        "from iglovikov_helper_functions.utils.image_utils import load_rgb, pad, unpad\n",
        "from iglovikov_helper_functions.dl.pytorch.utils import tensor_from_rgb_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdS-B03Az-r-"
      },
      "outputs": [],
      "source": [
        "from cloths_segmentation.pre_trained_models import create_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oGB-uNz0TWQ"
      },
      "outputs": [],
      "source": [
        "model = create_model(\"Unet_2020-10-30\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5qFkOsH_tAs"
      },
      "outputs": [],
      "source": [
        "model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51ILYA4hY2fY"
      },
      "outputs": [],
      "source": [
        "image = load_rgb(img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIlyE-3x6sKy"
      },
      "outputs": [],
      "source": [
        "#print(img)\n",
        "print(image)\n",
        "\n",
        "#files.view(keys[-1])\n",
        "#image = np.array(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vu1YBo2d1-32"
      },
      "outputs": [],
      "source": [
        "\n",
        "imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAYpUQPv_he3"
      },
      "outputs": [],
      "source": [
        "transform = albu.Compose([albu.Normalize(p=1)], p=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8NFud2YAUlP"
      },
      "outputs": [],
      "source": [
        "padded_image, pads = pad(image, factor=32, border=cv2.BORDER_CONSTANT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CN3CF4U9Avh6"
      },
      "outputs": [],
      "source": [
        "x = transform(image=padded_image)[\"image\"]\n",
        "x = torch.unsqueeze(tensor_from_rgb_image(x), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OByo1iaAwJD"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  prediction = model(x)[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzWS6PVLBKkX"
      },
      "outputs": [],
      "source": [
        "mask = (prediction > 0).cpu().numpy().astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuPeLMiNCfPV"
      },
      "outputs": [],
      "source": [
        "mask = unpad(mask, pads)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAxcjtc4BOSQ"
      },
      "outputs": [],
      "source": [
        "imshow(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdBTqaqKDZpU"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "# mask = (prediction > 0).cpu().numpy().astype(np.uint8)\n",
        "# cv2.imshow(\"Window\",mask_new)\n",
        "\n",
        "mask_new=cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB) * 255\n",
        "\n",
        "info = np.info(mask.dtype)\n",
        "data = mask_new\n",
        "\n",
        "\n",
        "\n",
        "cv2_imshow(mask_new)\n",
        "cv2.imwrite('/content/gdrive/MyDrive/content/mask.png',mask_new)\n",
        "# cv2.imwrite('/path/to/destination/image.png',image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EF0eAUZkBn4U"
      },
      "outputs": [],
      "source": [
        "dst = cv2.addWeighted(image, 1, (cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB) * (0, 255, 0)).astype(np.uint8), 0.5, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cugImqMiB8-q"
      },
      "outputs": [],
      "source": [
        "imshow(dst)\n",
        "dst_bgr = cv2.cvtColor(dst, cv2.COLOR_RGB2BGR)\n",
        "cv2.imwrite(\"/content/gdrive/MyDrive/clothkart/dst.png\",dst_bgr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0h2Y-oOCnXJ"
      },
      "outputs": [],
      "source": [
        "imshow(np.hstack([image, cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB) * 255, dst]))\n",
        "mask_new=cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB) * 255\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHQp_Q1L930Y"
      },
      "outputs": [],
      "source": [
        "Shirt='/content/gdrive/MyDrive/clothkart/cloth6.jpeg'\n",
        "mask_photo='/content/gdrive/MyDrive/clothkart/dst.png'\n",
        "# changing for design\n",
        "design = cv2.imread(Shirt)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeGMUdBa8nvw"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "frame = cv2.imread(mask_photo)\n",
        "hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# define range of green color in HSV\n",
        "lower_green = np.array([25, 52, 72])\n",
        "upper_green = np.array([102, 255, 255])\n",
        "# Threshold the HSV image to get only blue colors\n",
        "mask_white = cv2.inRange(hsv,lower_green, upper_green)\n",
        "mask_black = cv2.bitwise_not(mask_white)\n",
        "\n",
        "#converting mask_black to 3 channels\n",
        "W,L = mask_black.shape\n",
        "mask_black_3CH = np.empty((W, L, 3), dtype=np.uint8)\n",
        "mask_black_3CH[:, :, 0] = mask_black\n",
        "mask_black_3CH[:, :, 1] = mask_black\n",
        "mask_black_3CH[:, :, 2] = mask_black\n",
        "\n",
        "cv2_imshow(frame)\n",
        "cv2_imshow(mask_black_3CH)\n",
        "\n",
        "dst3 = cv2.bitwise_and(mask_black_3CH,frame)\n",
        "cv2_imshow(dst3)\n",
        "\n",
        "#///////\n",
        "W,L = mask_white.shape\n",
        "mask_white_3CH = np.empty((W, L, 3), dtype=np.uint8)\n",
        "mask_white_3CH[:, :, 0] = mask_white\n",
        "mask_white_3CH[:, :, 1] = mask_white\n",
        "mask_white_3CH[:, :, 2] = mask_white\n",
        "\n",
        "cv2_imshow(mask_white_3CH)\n",
        "dst3_wh = cv2.bitwise_or(mask_white_3CH,dst3)\n",
        "cv2_imshow(dst3_wh)\n",
        "\n",
        "#/////////////////\n",
        "\n",
        "# changing for design\n",
        "design = cv2.imread(Shirt)\n",
        "design = cv2.resize(design, mask_black.shape[1::-1])\n",
        "cv2_imshow(design)\n",
        "\n",
        "design_mask_mixed = cv2.bitwise_or(mask_black_3CH,design)\n",
        "cv2_imshow(design_mask_mixed)\n",
        "\n",
        "final_mask_black_3CH = cv2.bitwise_and(design_mask_mixed,dst3_wh)\n",
        "cv2_imshow(final_mask_black_3CH)\n",
        "\n",
        "\n",
        "cv2.waitKey()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYz4QaX3mcwl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFhOR2iHmasx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}